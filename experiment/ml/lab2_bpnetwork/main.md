# å¯¼å…¥ç›¸å…³åº“


```python
pip install sklearn
```

    Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple
    Requirement already satisfied: sklearn in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (0.0)
    Requirement already satisfied: scikit-learn in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from sklearn) (1.0.2)
    Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from scikit-learn->sklearn) (3.1.0)
    Requirement already satisfied: numpy>=1.14.6 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.21.6)
    Requirement already satisfied: joblib>=0.11 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.1.0)
    Requirement already satisfied: scipy>=1.1.0 in /home/ma-user/anaconda3/envs/python-3.7.10/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.7.3)
    [33mWARNING: You are using pip version 20.3.3; however, version 22.2.2 is available.
    You should consider upgrading via the '/home/ma-user/anaconda3/envs/python-3.7.10/bin/python -m pip install --upgrade pip' command.[0m
    Note: you may need to restart the kernel to use updated packages.
    


```python
from MLP import MLP
import sklearn
from utils.Data import DataClass, DataSet, DataSpliter
import numpy as np
from sklearn.datasets import load_iris, load_wine   # æ³¨æ„æ˜¯å¯¼å…¥çš„æ•°æ®é›†
import logging
from matplotlib import pyplot as plt
logging.disable(logging.WARNING)    # ç¦ç”¨ DataSet å®šä¹‰çš„ Logging
from time import time
```

- è®¾ç½®æ‰“å°ç»“æœçš„å‡½æ•°


```python
def trainResultPrint(dataSetName: str, trainingTime: int, trainacc: float, testacc: float, lr: float, epochNum: int):
    print(" * {:s} æ•°æ®é›†çš„è®­ç»ƒç»“æœï¼š".format(dataSetName))
    print("    - è®­ç»ƒæ—¶é•¿ä¸º:          {:.2f} s".format(trainingTime))
    print("    - è¿­ä»£æ€»æ¬¡æ•°ä¸º:        {:d} ".format(epochNum))
    print("    - å­¦ä¹ ç‡ä¸º:            {:.6f} ".format(lr))
    print("    - è®­ç»ƒé›†ä¸Šçš„å‡†ç¡®ç‡ä¸º:  {:.2%} ".format(trainacc))
    print("    - æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º:  {:.2%} ".format(testacc))
    print()
```

# é¸¢å°¾èŠ±æ•°æ®é›†
- å¯¼å…¥é¸¢å°¾èŠ±æ•°æ®é›†


```python
dataset_iris = load_iris()
feature_iris = dataset_iris.data
label_iris = dataset_iris.target
labelName_iris = dataset_iris.target_names
title_iris = ["sepal length in cm", "sepal width in cm", "petal length in cm", "petal width in cm"]
```

- æ„å»ºï¼Œåˆ’åˆ†æ•°æ®é›†


```python
dataset_iris = DataSet(feature_iris, label_iris, title_iris)
feature_iris, label_iris = dataset_iris.getFeatureAndLabel()
trainFeatureSet, trainLabelSet, testFeatureSet, testLabelSet = DataSpliter.trainAndTestSetSpliter_bareData(feature_iris, label_iris)
```

- æ„å»ºæ¨¡å‹


```python
st = time()
md = MLP(n_input = 4, n_hidden = 30, n_output = 3)
lr = 0.001
epochNum = 5000
md.optimize(trainFeatureSet, trainLabelSet, epochNum = epochNum, lr = lr, decay = "none", printMsg = True)
acc_train = md.eval(trainFeatureSet, trainLabelSet)
acc_test = md.eval(testFeatureSet, testLabelSet)
ed = time()
```

     + å½“å‰æ˜¯ç¬¬ 1000 æ¬¡è¿­ä»£
     + å½“å‰æ˜¯ç¬¬ 2000 æ¬¡è¿­ä»£
     + å½“å‰æ˜¯ç¬¬ 3000 æ¬¡è¿­ä»£
     + å½“å‰æ˜¯ç¬¬ 4000 æ¬¡è¿­ä»£
     + å½“å‰æ˜¯ç¬¬ 5000 æ¬¡è¿­ä»£
    

- è®­ç»ƒç»“æœ


```python
trainResultPrint("é¸¢å°¾èŠ±", ed - st, acc_train, acc_test, lr, epochNum)
```

     * é¸¢å°¾èŠ± æ•°æ®é›†çš„è®­ç»ƒç»“æœï¼š
        - è®­ç»ƒæ—¶é•¿ä¸º:          21.14 s
        - è¿­ä»£æ€»æ¬¡æ•°ä¸º:        5000 
        - å­¦ä¹ ç‡ä¸º:            0.001000 
        - è®­ç»ƒé›†ä¸Šçš„å‡†ç¡®ç‡ä¸º:  96.19% 
        - æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º:  100.00% 
    
    

å‡æ–¹æŸå¤±æ›²çº¿


```python
y_iris = md.getTrainLoss()
plt.plot(y_iris)
plt.title("MSELoss curve")
plt.rcParams['figure.figsize'] = (20.0, 12.0)
plt.show()
```


    
![png](main_files/main_14_0.png)
    


# çº¢é…’æ•°æ®é›†
- è¯»å–æ•°æ®


```python
dataset_wine = load_wine()
feature_wine = dataset_wine.data
label_wine = dataset_wine.target
labelName_wine = dataset_wine.target_names
title_wine = ["Alcohol", "Malic acid", "Ash", "Alcalinity of ash", "Magnesium", "Total phenols", "Flavanoids", "Nonflavanoid phenols", "Proanthocyanins", "Color intensity", "Hue", "OD280/OD315 of diluted wines", "Proline"]
```

- æ„å»ºæ•°æ®é›†ï¼Œåˆ’åˆ†æ•°æ®


```python
dataset_wine = DataSet(feature_wine, label_wine, title_wine)
dataset_wine.rescaling()
feature_wine, label_wine = dataset_wine.getFeatureAndLabel()
trainFeatureSet, trainLabelSet, testFeatureSet, testLabelSet = DataSpliter.trainAndTestSetSpliter_bareData(feature_wine, label_wine, trainRatio = 0.7)
```

- æ¨¡å‹è®­ç»ƒ


```python
st = time()
md = MLP(n_input = 13, n_hidden = 50, n_output = 3)
lr = 0.0001
epochNum = 5000
md.optimize(trainFeatureSet, trainLabelSet, epochNum = 5000, lr = 0.0001, decay = "none", printMsg = True)
acc = md.eval(testFeatureSet, testLabelSet)
ed = time()
trainacc = md.eval(trainFeatureSet, trainLabelSet)
testacc = md.eval(testFeatureSet, testLabelSet)
```

     + å½“å‰æ˜¯ç¬¬ 1000 æ¬¡è¿­ä»£
     + å½“å‰æ˜¯ç¬¬ 2000 æ¬¡è¿­ä»£
     + å½“å‰æ˜¯ç¬¬ 3000 æ¬¡è¿­ä»£
     + å½“å‰æ˜¯ç¬¬ 4000 æ¬¡è¿­ä»£
     + å½“å‰æ˜¯ç¬¬ 5000 æ¬¡è¿­ä»£
    

- è®­ç»ƒç»“æœ


```python
trainResultPrint("çº¢é…’(UCI)", ed - st, trainacc, testacc, lr, epochNum)
```

     * çº¢é…’(UCI) æ•°æ®é›†çš„è®­ç»ƒç»“æœï¼š
        - è®­ç»ƒæ—¶é•¿ä¸º:          33.54 s
        - è¿­ä»£æ€»æ¬¡æ•°ä¸º:        5000 
        - å­¦ä¹ ç‡ä¸º:            0.000100 
        - è®­ç»ƒé›†ä¸Šçš„å‡†ç¡®ç‡ä¸º:  99.19% 
        - æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º:  92.73% 
    
    

- æŸå¤±æ›²çº¿


```python
y_wine = md.getTrainLoss()
plt.plot(y_wine)
plt.rcParams['figure.figsize'] = (20.0, 12.0)
plt.show()
```


    
![png](main_files/main_24_0.png)
    

